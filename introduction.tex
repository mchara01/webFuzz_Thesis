\chapter{Introduction}
\pagenumbering{arabic} % start arabic page numbering
\minitoc
\vspace*{1cm}

In the introductory chapter to this thesis, we analyse what motivated us to explore grey-box fuzzing to begin a research project in this area. We further discuss related studies in the field of fuzzing, the contribution that our thesis makes to better understanding it while outlining the eight chapter topics that are addressed.

This thesis is focused on the core functionalities of the fuzzing tool so we do not delve into details about the \emph{instrumentation} or the automate bug injection tool used during the evaluation in Chapter ~\ref{sec:evaluation}, as they are beyond the scope of our research.

% NEW SECTION
\section{Motivation}

Despite much research done in web applications security flaws in recent years, vulnerabilities in software are still commonplace. The overall number of new vulnerabilities in 2019 (20,362) increased by \emph{17.6}\% compared to 2018 (17,308) and by \emph{44.5}\% compared to 2017 (14,086) ~\cite{vulnerabilities2019state,owasp2017}. A major cause of this phenomenon in web-apps comes from the source code itself which more often than not is written in unsafe languages, such as PHP or JavaScript ~\cite{vulnerabilities2019state} opening the door to vulnerabilities. Many programmers do not have adequate expertise in secure coding, so they leave applications with vulnerabilities. 

As the occurrence of security vulnerabilities in web applications has increased to an all-time high with damages inflicted costly, an automated approach is required to keep up with the number of web-apps that need vetting for vulnerabilities. DARPA funded the Cyber Grand Challenge competition in 2016 ~\cite{darpa2016cgc}, with millions of dollars in prize money, to further research on automated vulnerability finding and patching. There are many bug bounty programs and capture the flag competitions dedicated to securing applications that power large organizations ~\cite{bugbounty}. Our research hopes to take advantage of this heightened interest and renewed awareness.

Several approaches exist for protecting web applications by detecting and removing vulnerabilities. They usually fall into three main categories: static, concolic, and dynamic analysis systems. Static analysis tools detect vulnerabilities in source code by examining the code without executing the program ~\cite{balzarotti2008saner,jovanovic2006pixy,jovanovic2006precise,medeiros2014mining,medeiros2016dekant}.
Concolic execution combines both concrete execution (\ie normal code execution) and symbolic execution. Tools that utilize symbolic execution, instead of feeding the program with expected inputs, one supplies symbols representing arbitrary values ~\cite{king1976symoblic,Godefroid2008AutomatedWF}. Dynamic analysis, including fuzzing, where the web-app is monitored while exercised with malformed data in an automated fashion ~\cite{mller1990fuzz,godefroid2012sage,doupe2012enemy,duchene2014kameleonfuzz}.

Fuzzing is now widely recognised as an essential process for discovering hidden bugs in computer software. Automated software testing or fuzzing is a tried and tested method of generating or mutating inputs and passing them to programs in search of bugs. The spark in the fuzzing 'revolution' to discover bugs in software through an automated process has precipitated with the introduction of American Fuzzy Lop (AFL) ~\cite{zalewski2015american}, a state-of-the-art fuzzer that produces feedback during fuzzing by leveraging \emph{instrumentation} of the analysed program. 

In creating this \textit{feedback loop}, fuzzers can significantly improve their performance by determining whether an input is interesting, namely, it triggers a new code path, and uses that input to produce other test cases. That is called coverage guided fuzzing.

Software testing plays a vital role in the software development cycle because when vulnerabilities are present, they can cause severe or irreparable consequences. By exploiting software bugs, adversaries can perform data breaches, install malicious malware or even take complete control of a device ~\cite{hackerscontrol,facebook_data_breach}.

Detecting bugs before they get exploited is a viable but demanding task. Mainly because bugs are triggered when an unexpected input is given to the program, something that is difficult to fully simulate through statically written unit tests. That is down to the fact unit tests usually revolve around expected inputs to test the intended functionality of code ~\cite{aschermann2019nautilus}.

Although automated software testing has become a burgeoning field of research, it still has a long way to go, especially for web applications ~\cite{doupe2010johnny}. As the Internet infrastructure expands, much more of the software written in native code (pre-compiled program in the CPU's \emph{machine language}) is migrating to web applications. This process attracts many more malicious attacks on web applications. This predicates a strong need for the development of automated vulnerabilities scanners that target web applications.
 
% NEW SECTION REPHRASE
\section{Related Work}
Fuzzers recently developed try to optimize the fuzzing process by proposing different methodologies ~\cite{godefroid2012sage, stephens2016driller, rawat2017vuzzer, aschermann2019nautilus, aschermann2019redqueen, hoffman2020Was, osterlund2020parmesan}. 
For example, most fuzzers take advantage of \emph{instrumentation} at the binary or source level. This is done by inserting code in the program to receive feedback when a code block is
triggered so the fuzzer can adjust the generated inputs to improve code coverage. 
Other fuzzing methodologies utilize symbolic/concolic execution for extracting useful information about the program, using that information to improve the input generation process ~\cite{Godefroid2008AutomatedWF,stephens2016driller,godefroid2005dart,godefroid2012sage}. However, all these fuzzers currently target finding vulnerabilities in native code while web applications - which do not run on native code - have more-or-less been neglected. A more detailed analysis is given in Chapter ~\ref{sec:relatedwork}.

Traditionally, fuzzers come under three categories; black-, white- or grey-box which are clearly defined for native applications. When it comes to web applications grey-box approaches have not been defined, so our mission was to produce a prototype process inspired by work done on native applications, more precisely AFL.

\section{Contributions}
In this thesis, \pname{} is proposed. It is a prototype grey-box fuzzing tool for web applications. Today, the only fuzzers available for web applications are developed to behave in a black-box fashion ~\cite{doupe2010johnny}. That is to say, they use brute force to bombard their targets with URLs that embed known web-attack payloads. There have been breakthroughs with white-box fuzzing also ~\cite{navex2018,Borges2018BaZINGAWF}, that combine static analysis and concolic testing with fuzzing.

Unlike the Black-/White-box fuzzing approach, \pname{} initially instruments the targeted web application by adding code that tracks all control flows triggered by an input and notifies the fuzzer, accordingly. Notifications can be embedded in the web application's HTTP response using custom headers or outputted to a shared log file or memory region. Subsequently, the fuzzer sends requests to the target and analyses the responses to detect any interesting requests that would later help to improve the code coverage and as a result, trigger vulnerabilities embedded deep in the web application's code.

The following contributions are made in this thesis:

\begin{enumerate}

\item We design, implement and evaluate \pname{}, a prototype grey-box fuzzer created for discovering vulnerabilities in web applications. \pname{} applies \emph{instrumentation} on the target web application for guiding the entire fuzzing process. \emph{Instrumentation} can be applied to the Abstract Syntax Tree (AST) level of PHP-based web applications for establishing a \emph{feedback loop} and utilizing it to increase code coverage.
\item We thoroughly evaluate \pname{} in terms of efficiency in finding unknown bugs, of code coverage and throughput. For a better understanding of the measurement capabilities of \pname{}, we compared our results with three existing black-box web-application vulnerability scanners. Indicatively, \pname{} can cover about 21.5\% of WordPress, which has a codebase of approximately half a million lines of PHP code, in 4.2 days (6000 minutes) of fuzzing. As expected, \pname{} is slower, in terms of throughput, due to the involved \emph{instrumentation}. Another popular fuzzer, Wfuzz ~\cite{wfuzz} is three times faster when fuzzing Drupal. This is to be expected since the reduction of the throughput from the \emph{instrumentation} pays off in increased coverage in the long run. Finally, \pname{}, compared to the other three fuzzers, detects more injected vulnerabilities (30 with the second one being Wfuzz with 28) during a fuzzing session lasting 65 hours. The evaluation of \pname{} is detailed in Chapter ~\ref{sec:evaluation}.
\item To foster further research in the field \pname{} will be released as open-source.

\end{enumerate}

 \section{Thesis Outline}
This thesis has eight chapters. In the first chapter, we presented our inspiration for undertaking this research, related work on the topic and the contributions made in this thesis. In the second chapter, we state any relevant background information required to grasp the perspective of this work. 

Continuing to the third chapter, the architecture of the tool is discussed on a higher level without delving into too much implementation detail. The fourth chapter is dedicated to discussing the technical aspects of the fuzzing tool developed. The fifth chapter evaluates how well webFuzz performs in finding bugs, code coverage and throughput against other fuzzers. 

In the sixth chapter, we review the limitations faced during the research process while unfurling what future plans we have for our tool. In the seventh chapter, we elaborate on the related work made in the area of fuzzing in recent years. In the eighth and final chapter, we summarise and reflect on the research done, concluding on the evaluation of our approach.