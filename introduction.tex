\chapter{Introduction}
\pagenumbering{arabic} % start arabic page numbering
\minitoc
\vspace*{1cm}

In the introductory chapter to this thesis we analyse what motivated us to explore grey-box fuzzing to begin a research project in this area. We further discuss related studies in the field of fuzzing, the contribution that our thesis makes to understanding it while outlining the eight chapter topics that are addressed.

% NEW SECTION
\section{Motivation}

Despite much research being done in web applications security flaws in the past years, vulnerabilities in software are still commonplace. This is because the overall number of new vulnerabilities in 2019 (20,362) increased by 17.6\% compared to 2018 (17,308) and by 44.5\% compared to 2017 (14,086) ~\cite{vulnerabilities2019state,owasp2017}. A major cause of this problems in web-apps, comes from the source code itself which often written in unsafe languages, such as PHP or JavaScript ~\cite{vulnerabilities2019state} leading to the existence of vulnerabilities. Also, many programmers do not have adequate knowledge about secure coding, so they leave applications with vulnerabilities. 

As the occurrence of security vulnerabilities in web applications has increased to an all-time high and as the damages by their exploitation can be costly, an automated approach is required to keep up with the amount of the amount of web-apps that must be vetted for vulnerabilities. DARPA funded the Cyber Grand Challenge competition in 2016, with millions of dollars in prize money, to further research focusing on automated vulnerability finding and patching, showing the importance of research in this area. Also, there are many bug bounty programs and capture the flag competitions dedicated to help secure the application the power great organizations ~\cite{bugbounty}.

Several approaches exist with the goal of protecting web applications by detecting and removing vulnerabilities. They usually fall into three main categories: static, concolic, and dynamic analysis systems. Static analysis tools detect vulnerabilities in source code by examining the code without executing the program ~\cite{balzarotti2008saner,jovanovic2006pixy,jovanovic2006precise,medeiros2014mining,medeiros2016dekant}
Concolic execution combines both concrete execution (\ie normal code execution) and symbolic execution. Tools that utilize symbolic execution, instead of feeding the program with expected inputs, one supplies symbols representing arbitrary values ~\cite{king1976symoblic,Godefroid2008AutomatedWF}. Dynamic analysis, including fuzzing, were the web-app is monitored while exercised with malformed data in an automated fashion ~\cite{mller1990fuzz,godefroid2012sage,doupe2012enemy,duchene2014kameleonfuzz}.

Fuzzing is now widely recognised as an essential process for discovering hidden bugs in computer software. Automated software testing or fuzzing is a tried and tested method of generating or mutating inputs and passing them to programs in search of bugs. The spark in the fuzzing 'revolution' to discover bugs in software in an automated process has been precipitated with the introduction of AFL ~\cite{zalewski2015american}, a state-of-the-art fuzzer that produces feedback during fuzzing by leveraging instrumentation of the analysed program. By creating this \textit{feedback loop}, fuzzers can significantly improve their performance as they can determine whether an input is interesting, namely it triggers a new code path, and uses that input to produce other test cases. This approach, were in a loop we try to inject the new inputs in order to cover all existing code branches is called coverage guided fuzzing.

Software testing plays a vital role in the software development cycle because when vulnerabilities are present, they can cause severe or irreparable consequences. By exploiting software bugs, adversaries can perform data breaches, install malicious malware or even take complete control of a device ~\cite{hackerscontrol,facebook_data_breach}.

Detecting bugs before they are exploited is a possible but demanding task. Mainly because bugs are triggered when an unexpected input is given to the program, something which is difficult to fully simulate through statically written unit tests. This is down to the fact unit tests usually revolve around expected inputs to test the intended functionality of code ~\cite{aschermann2019nautilus}.

Although automated software testing has become an attractive field of research, it still has a long way to go, especially for web applications ~\cite{doupe2010johnny}. As the Internet infrastructure expands, much more of the software written in native code (pre-compiled program in the CPU's machine language) is migrating to web applications. This process attracts many more malicious attacks on web applications. This predicates a strong need for the development of automated vulnerabilities scanners that target web applications.
 
% NEW SECTION REPHRASE
\section{Related Work}
Numerous fuzzers recently developed try to optimize the fuzzing process by proposing different methodologies ~\cite{godefroid2012sage, stephens2016driller, rawat2017vuzzer, aschermann2019nautilus, aschermann2019redqueen, hoffman2020Was, osterlund2020parmesan}. 
For example, most fuzzers take advantage of instrumentation at the binary or source level. This is done by inserting code in the program to receive feedback when a code block is
triggered so the fuzzer can adjust the generated inputs to improve code coverage. 
Other fuzzing methodologies utilize symbolic/concolic execution for extracting useful information about the program and use that information for improving the input generation process ~\cite{Godefroid2008AutomatedWF,stephens2016driller,godefroid2005dart,godefroid2012sage}. However, all these fuzzers are currently targeted towards finding vulnerabilities in native code while web applications - which do not run on native code - have more-or-less been neglected. A more detailed analysis is given in Chapter ~\ref{sec:relatedwork}.

Traditionally, fuzzers come under three categories; black-, white- or grey-box which are clearly defined for native applications. When it comes to web applications grey-box approaches have not been defined, so our mission was to produce a prototype process inspired by work done on native applications, more precisely AFL.

\section{Contributions}
In this thesis, \pname{} is proposed. It is a prototype grey-box fuzzing tool for web applications. Today, the only fuzzers available for web applications are developed to behave in a black-box fashion ~\cite{doupe2010johnny}. That is to say they use brute force to bombard their targets with URLs that embed known web-attack payloads. Recently, there were breakthroughs with white-box fuzzing also ~\cite{navex2018,Borges2018BaZINGAWF}, that combine static analysis and concolic testing with fuzzing.

Unlike the Black-/White-box fuzzing approach, \pname{} initially instruments the targeted web application by adding code that tracks all control flows triggered by an input and notifies the fuzzer, accordingly. Notifications can be embedded in the web application's HTTP response using custom headers or outputted to a shared log file or memory region. Subsequently, the fuzzer begins sending requests to the target and analyses the responses to detect any interesting requests that would later help to improve the code coverage and as a result, trigger vulnerabilities embedded deep in the web application's code.

The following contributions are made in this thesis:

\begin{enumerate}

\item We design, implement and evaluate \pname{}, a prototype grey-box fuzzer realized for discovering vulnerabilities in web applications. \pname{} applies instrumentation on the target web application for guiding the entire fuzzing process. Instrumentation can be applied on the AST level of PHP-based web applications for creating a feedback loop and utilizing it to increase code coverage.
\item We thoroughly evaluate \pname{} in terms of coverage, throughput and efficiency in finding unknown bugs. For a better understanding of the measured capabilities of \pname{} we compare our results with three existing web-application fuzzers. \pname{} is the only fuzzer that
reports coverage information. Specifically, \pname{} can cover about 21.5\% of WordPress, which has a codebase of approximately half a million lines of PHP code, in 50 hours of fuzzing. As expected, \pname{} is slower, in terms of throughput, due to the involved instrumentation. In fact, another popular fuzzer, Wfuzz ~\cite{wfuzz} is three times faster when fuzzing Drupal, but this is something to be expected, since reduction of the throughput due to the instrumentation pays off in increased coverage in the long run. Finally, \pname{}, compared to the other three fuzzers, finds the most injected vulnerabilities (30 with the second one being Wfuzz with 28) during a fuzzing session that lasts 65 hours. The evaluation of \pname{} can be seen in detail in Chapter ~\ref{sec:evaluation}
\item To foster further research in the field, \pname{} will be released as open source.

\end{enumerate}

% SHOULD WE DO ANOTHER SECTION HERE? CLARIFICATIONS SPECIFICATIONS
This thesis is focused on the core functionalities of the fuzzing tool thus we do not delve into much details about the instrumentation and the automate bug injection tool used during the evaluation in Chapter ~\ref{sec:evaluation}.
 
Following a "borderline" rejection on the initial submission of this thesis at CODASPY 2021, the due modifications and clarifications were made, giving us confidence that a more comprehensive study will be accepted when resubmitted to DIMVA 2021 for publication.

\section{Thesis Outline}
This thesis has eight chapters. In the first chapter we present our inspiration for undertaking this research, related work on the topic and the contributions made in this thesis. In the second chapter we state any relevant background information required to grasp the perspective of this work. 

Continuing to the third chapter, the architecture of the tool is discussed on a higher level without delving into too much implementation details. The fourth chapter is dedicated to discussing the technical aspects of the fuzzing tool developed. The fifth chapter is an evaluation to see how well \pname{} performs in terms of finding bugs, code coverage and throughput against other fuzzers. 

In the sixth chapter, we review the limitations faced during the research process while unfurling what future plans we have for our tool. In the seventh chapter we elaborate on the related work made in the area of fuzzing in recent years. In the eighth and final chapter we summarise and reflect on the research done, concluding on the evaluation of our approach.