\chapter{Related Work}
\label{sec:relatedwork}
\minitoc
\vspace*{1cm}

In this chapter, all relevant, acclaimed or related academic work achieved in recent years at research level in the field of fuzzing is referenced below. This chapter divides into two sections; generic fuzzing on \emph{native code} and fuzzing web applications. Taking this into consideration, we present our approach compared to what went before.

\section{Generic Fuzzing}
Fuzzing has been perceived through several techniques and algorithms over the years. Firstly, we have the black-box fuzzers ~\cite{householder2012probability,sparks2007automated,woo2013scheduling} which are unaware of the fuzz target's internals and try to trigger vulnerabilities by randomly generating the inputs. While the black-box fuzzers category might not be as performant as others, they offer the advantage of compatibility with any program ~\cite{osterlund2020parmesan,rawat2017vuzzer}. The other two categories are white- and grey-box fuzzers. These two leverage \emph{instrumentation} to obtain feedback concerning the inputs' precision in discovering unseen paths. 

It has been proven that feedback is vital for a fuzzer's performance since it can be used to steer the fuzzer towards exploring new code paths, resulting in better code coverage also known as
coverage-based fuzzers. Otherwise, we have the directed based fuzzers that use feedback to direct the fuzzer towards particular execution paths ~\cite{godefroid2005dart}.

A renowned fuzzer that is classified as coverage-based is AFL ~\cite{zalewski2015american}. AFL is a state-of-the-art grey-box fuzzer which is the foundation for the majority of recently-proposed research. However, AFL fails to intelligently generate inputs to explore deep paths in programs hidden behind checksums or \emph{magic number if} statements.

Having that in mind, recent research makes use of symbolic and concolic execution to enhance the input generation procedure by extracting valuable information about the program. Some examples consist of DRILLER ~\cite{stephens2016driller}, DART ~\cite{godefroid2005dart} and SAGE ~\cite{godefroid2012sage}. DRILLER is also an example of a hybrid vulnerability searching tool as it combines fuzzing and symbolic execution.

Despite efforts to improve the fuzzing process with the use of symbolic/concolic execution-based fuzzers, these types of fuzzers suffer from scalability problems because when fuzzing sizeable targets, we notice the phenomenon of state/path explosion ~\cite{Clarke2012}. This problem is observed when the number of state variables in the system increases, the size of the system state space grows exponentially making it impossible to explore the entire state space with limited resources of time and memory. 

While trying to explore every path in the code (\ie for a conditional branch, they often create an input that causes the branch to be taken and another that does not) they succumb to path explosion, greatly limiting their scalability.

Consequently, other research proposals try to accomplish what symbolic/concolic execution-based fuzzers offer with a less expensive approach. One example is REDQUEEN ~\cite{aschermann2019redqueen} that utilizes the input-to-state correspondence to infer the values that can later be used to try and control them. Another such example is VUzzer ~\cite{rawat2017vuzzer}, an application-aware evolutionary fuzzer that leverages control and data-flow features using static and dynamics analysis to infer fundamental properties of the fuzz target.

\section{Web Applications Fuzzing}
Even though a huge effort is directed toward building fuzzers with the aim to weed out vulnerabilities in \emph{native code}, little attention has been given to web application bugs. Tools currently available that target web application vulnerabilities behave predominantly in a black-box fashion, therefore, they are unable to uncover vulnerabilities that are embedded deep into a web application ~\cite{bau2010state, doupe2010johnny}.
 
Such as SecuBat ~\cite{kals2006secubat}, a web vulnerability scanner that uses a black-box approach to detect SQL injection(SQLi) and Cross-Site Scripting(XSS) vulnerabilities. Another example is KameleonFuzz ~\cite{duchene2014kameleonfuzz}, a black-box fuzzer for web vulnerabilities targeting XSS susceptibilities.

There have been attempts to overcome the shortcomings of black-box techniques. Doup√© et al. ~\cite{doupe2012enemy} proposed a way to navigate through a web application's states to discover whether an input is interesting by noticing the changes in the output. 

Alternatively, there is the white-box approach to consider with access to the web application's source code. Kieyzun et al. ~\cite{kieyzun2009automatic} used a technique exploiting information about the code that automatically generates inputs targeting SQLi and XSS vulnerabilities. 

Moreover, Artzi et al. ~\cite{artzi2010finding} developed another tool for discovering web
application vulnerabilities by collecting information about the target extracted through concrete and symbolic execution.

White-box methods outperform black-box approaches by having access to the source code of the target being fuzzed. However, black-box processes are more scalable when the source code is not 
available. 

To conclude, web vulnerability scanners are also realized through static analysis tools~\cite{balzarotti2008saner,jovanovic2006pixy,jovanovic2006precise,medeiros2014mining,medeiros2016dekant}. Prime examples are Pixy ~\cite{jovanovic2006pixy} which uses static analysis at the source code
level to detect vulnerable code. Another tool combining static and dynamic analysis is Saner ~\cite{balzarotti2008saner} which tries to identify any sanitization processes that do not work as expected to, resulting in allowing attackers to introduce exploits.

Contrary to the above research work for identifying web vulnerabilities, our technique adopts the
grey-box approach. \pname{} \emph{instruments} the fuzz target to receive feedback on whether a generated input is interesting. These inputs were used to generate other test cases that resulted in wider code coverage that triggered more vulnerabilities (Chapter ~\ref{sec:evaluation}). 

Unlike other fuzzers mentioned that generate their own XSS payloads ~\cite{duchene2014kameleonfuzz}, our tool's  main objective is finding trigger points on the target web application and supplying them with known XSS payloads. 